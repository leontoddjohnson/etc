---
title: ungrading
weight: 3
---

# ungrading

The traditional letter grading (A-F) system is a relatively new practice that began *in America* in the late 19th century (Schneider & Hutt, 2014). Importantly, its roots are not in measuring student learning in such a way that benefits the student. On the contrary, grades are, by design, a way to rank or *grade* students (McNutt, 2022) as if it their knowledge should be [treated as a commodity](https://www.youtube.com/watch?v=BeTRp73gtp4)[^fn:usda-beef]. Among many other disservices (Kohn, 2011), this sort of thing undermines the student's individuality and their self worth. As a result, grades are explicitly in conflict with students' development of their "self-as-learner" that is pivotal to my teaching philosophy.

[^fn:usda-beef]: Consider, for example, the different USDA "grades" of meat. They give consumers a way to decide which version of a commodity to buy. Indeed, it is self-evident that the *grade* doesn't benefit the meat in any way.

As an alternative to grading in the traditional way, [Ungrading](https://www.youtube.com/watch?v=3JJHHCiSgVs) (Blum, 2020) has surfaced as a method specifically designed to focus on developing student learning as an attribute of the student, not as a good or service that can be exploited. Personally, I prefer to think of ungrading as the system by which we replace all instances of the term "grading" with "feedback".

## measuring learning

Ungrading and metacognition are inextricably linked. Indeed, our goal here is to assess student learning, and **the most qualified expert on a student's learning is themselves**, so their metacognitive evaluations are pivotal to the ungrading "process". The difficulty is that learning is incredibly difficult to quantify, so it is the instructors job then to translate metacognitive assets into quantitative measurements of learning. In particular, I prefer the following:

- use topic modeling on metacognitive survey responses to identify and quantify markers of student learning progress or stagnation
- analyze trends of red/yellow/green indicators on weekly metacognitive reports[^fn:metacog-page-1]
- aggregate improvements in student responses to the course learning objective listing question[^fn:metacog-page-2]
- review the complete/incomplete assignment markings in the grade book

[^fn:metacog-page-1]: On the [metacognition](../metacognition) page, refer to the metacognitive report survey questions.

[^fn:metacog-page-2]: On the [metacognition](../metacognition) page, refer to the metacognitive self-reflection survey questions.

Each of these can provide the student with a kind of gauge they can use to self-evaluate, but they also give me (the instructor) a self-check for whether my teaching methods are working; i.e., they help me determine whether students are learning *as a result of* my course offering.

### evidence

*In progress ...*

*As of April 2025, I'm still wrapping up my first semester implementing these processes. I'm also working on a computational solution that will present these measures into a web app using the Canvas API.*

## giving feedback

When students are given a "grade", it feels final. It is as if we are saying "this is how I would rate *you*, and that's just the way it is". It doesn't give the student a growth-informed feeling of "I am always improving, and this is helpful", which is more meaningful to a student's self-efficacy. So, instead of giving students a grade or a score for their assignments, I'll use the following process for each submission with help from teaching assistants (TAs)

1. Mark the submission with an E, M, R, or N based on the [EMRN rubric](https://docs.google.com/presentation/d/e/2PACX-1vTDNNNryzNZi1-VI_pRqLDla_T1X78lhcRKXqb85MEmYaV-XRdGPuJWRNsECi5ZVfxMFRV1JdJtzUA_/pub?start=false&loop=false&delayms=3000).
2. Give the student *detailed* feedback, providing suggestions for improvement, guidance, as well as recognizing jobs well done.\*
3. Allow the student to make adjustments and resubmit their work (within a reasonable time frame).\*
4. Repeat steps 1-3 until the student decides not to resubmit again.

*\* For steps 2-3, students will also share a metacognitive report.*

This approach, inspired by specifications grading (Nilson, 2014), empowers students with the opportunity to grow their knowledge base with every revision, and it also grants them ownership over their learning. I.e., they are not just given a "complete" designation for their submissions, they *earn* it. 

### meetings with students

Of course, the best way to evaluate (and guide) student learning is to meet with them one-on-one, and have a conversation about the subject matter. But for me, this is not tractable with the number of students I have. So, I use TAs to meet with students at least once for course project reviews. During these meetings, TAs are asked to "interview" students on their work, forcing them to talk about what they did and why they did it. By explaining, they are either learning, showcasing their learning, or discovering gaps in their learning.

### peer review

In addition to timely feedback from the instructor and TAs, it's been shown that peer review can be just as valuable a measure of self-assessment for both the student *and* the peer reviewer (Yan & and Carless, 2022). So, for the comprehensive course-wide projects, I require students to review, mark (using the EMRN rubric), and provide feedback on at least one other students' work. Not only does this give the student another perspective on their learning outcomes, but it also forces students to *use* what they learn when evaluating the work of another student.

Again, **projects do not have a final score/grade**. Rather, just like every other assignment, they are a mechanism by which students can practice what they learn, get feedback, and improve. The only difference with projects is that they are more involved and tend to be more in-depth.

# references

Susan D. Blum. (2020). Ungrading: Why Rating Students Undermines Learning (and What to Do Instead): Vol. First edition. West Virginia University Press. https://library.indianapolis.iu.edu/cgi-bin/proxy.pl?url=https://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=2640879&site=ehost-live

Kohn, A. (2011, November). *The Case Against Grades.* Alfie Kohn. https://www.alfiekohn.org/article/case-grades/

McNutt, C. (2022, August 8). *A brief history of grades and gradeless learning.* Human Restoration Project. https://www.humanrestorationproject.org/writing/a-brief-history-of-grades-and-gradeless-learning

Nilson, L.B. (2014). Specifications Grading: Restoring Rigor, Motivating Students, and Saving Faculty Time (1st ed.). Routledge. https://doi.org/10.4324/9781003447061

Schneider, J., & Hutt, E. (2013). *Making the grade: a history of the A–F marking scheme.* Journal of Curriculum Studies, 46(2), 201–224. https://doi.org/10.1080/00220272.2013.790480

Yan, Z., & and Carless, D. (2022). Self-assessment is about more than self: The enabling role of feedback literacy. Assessment & Evaluation in Higher Education, 47(7), 1116–1128. https://doi.org/10.1080/02602938.2021.2001431
